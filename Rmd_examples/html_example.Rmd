---
title: "Finding outliers in NY IPEDS circulation data at public institutions"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#load the tidyverse set of packages. 
library(tidyverse)

#read in the data
dat <- read_csv("../data/processed/IPEDS.csv")
```

Finding and isolating outliers for further investigation is an important part of data wrangling and analysis. It requires getting a general idea of the database, including wrangling and shaping data to create visualizations and tables.

I'll be using the tidyverse group of packages to do so. Below are a few functions that I'll be using regularly in this file:

- %>% - the pipe. This combines each step into a single statement. The result of the statement to the left or above the pipe is piped into the statement to the right or below.
- filter() - This function filters the data based on logical tests like == [equals], != [not equals], > [greater than], < [less than]. Functions that provide a logical result like is.na() [is a NA value], !is.na [is not a NA value], can also be used
- group_by() - This function creates groups based on categorical variables within the dataset. It allows us to group by state, highest degree offered by the institution, institution size, local, etc. It's useful for the next two functions.
- mutate() - change or add a new variable in the file. This can be used with summary functions like sum(), mean(), median() as well as arithmetic formulas. One other function is n() which provides a count.
- summarise() - instead of adding a new variable, this summarises the dataset based on the groups you've specified and the summary functions/formulas like sum(), mean(), median(), n(), etc.
- rename() - renames the columns. I'm using it to shorten the variable names.
- ggplot - this is the part of the tidyverse that creates plots and graphs. Each ggplot consists of aes() [aesthetics] which can contain the x values, y values, and other values like color or fill. 
- geom_???() - this specifies the visualizations. It's from the ggplot package
- arrange() - arranges data by a numeric variables by least to greatest. Adding the desc() function will arrange it in descending order.
- head() - results in first x number of rows. There's also tail() which results in the last x number of rows.

## Top five states for academic circulation

First, a national view of the circulation data.

```{r echo = FALSE}
dat %>% 
  filter(fyear == 2020) %>%         # filtering just for 2020
  group_by(state_abbreviation) %>%  # grouping by state
  summarise(n_instituions = n(),
    total_circ = sum(total_library_circulations_physical_and_digital_electronic, na.rm = TRUE),
            total_phys_circ = sum(total_physical_library_circulations_books_and_media, na.rm = TRUE),
            total_dig_circ = sum(total_digital_electronic_circulations_books_and_media, na.rm = TRUE)) %>% 
  arrange(desc(total_circ)) %>% 
  head(5)
```

## NY academic libraries - Bar chart and stacked bar chart example

Next we'll look at NYS academic libraries. We can see that they are split somewhat evenly between public institutions and private not-for-profit institutions. There are significantly less private for-profit institutions. 

```{r echo = FALSE}
dat %>% 
  filter(fyear == 2020 & !is.na(control_of_institution)) %>% 
  group_by(control_of_institution) %>% 
  mutate(count = n()) %>% 
  ggplot(aes(x = reorder(control_of_institution, count))) + # reorder reorders the plot so that the count goes from lowest to highest
  geom_bar() +
  xlab("control of institutions") # changing the x-axis lable
```

To go a bit farther, lets look at where these institutions are with a stacked bar chart.

```{r echo = FALSE}
dat %>% 
  filter(fyear == 2020 & !is.na(degree_of_urbanization_urban_centric_locale)) %>% 
  group_by(degree_of_urbanization_urban_centric_locale) %>% 
  mutate(count = n()) %>% 
  ggplot(aes(x = degree_of_urbanization_urban_centric_locale, fill = control_of_institution)) +
  geom_bar() +
  xlab("geographic locale") +
  coord_flip()
```

## Public academic libraries in NY circulation - Line/Time series example

The below chart now looks at total circulation in public academic libraries by the highest degree they offer. We're summing all instituions rather than getting the average. The masters degree looks a bit suspicious since it's high and then shoots back down.

```{r echo = FALSE}
dat %>% 
  filter(state_abbreviation == "NY" & control_of_institution == "Public") %>% 
  group_by(highest_degree_offered, fyear) %>% 
  summarise(n_instituions = n(),
    total_circ = sum(total_library_circulations_physical_and_digital_electronic, na.rm = TRUE),
            total_phys_circ = sum(total_physical_library_circulations_books_and_media, na.rm = TRUE),
            total_dig_circ = sum(total_digital_electronic_circulations_books_and_media, na.rm = TRUE)) %>%
  ggplot(aes(x = fyear, y = total_circ, color = highest_degree_offered)) +
  geom_line() +
  xlab("fiscal year") + ylab("circulation")
```

## Looking for outliers - Box plot examples

Since that decrease in circulation for masters degree institutions seems suspicious lets look a little more closely at 2019 and 2020. I'm using a box plot here because it will tell me the median, the quartiles and highlight how many and how far the outliers are to the 2nd and 3rd quartile.

```{r echo = FALSE}
dat %>% 
  filter(state_abbreviation == "NY" & control_of_institution == "Public" & fyear > 2018) %>% 
  rename(total_circ = total_library_circulations_physical_and_digital_electronic,
         dig_circ = total_electronic_library_collections_books_databases_media_and_serials,
         phys_circ = total_physical_library_circulations_books_and_media) %>% 
  ggplot(aes(x = highest_degree_offered, y = total_circ)) +
  geom_boxplot() + 
  scale_x_discrete(labels = scales::wrap_format(10)) +
  xlab("circulation")
```

There is definitely multiple outliers in the masters degree granting institutions. 

---

## Calculating percentages and finding the largest outlier

Lets find out what the largest outlier is. This is also an example of using inline R commands within natural language text.

```{r echo = FALSE}
# Creating a new variable to show you how to use inline code

dat2 <- dat %>% 
  filter(state_abbreviation == "NY" & control_of_institution == "Public") %>% 
  mutate(perc_dig_circ = total_digital_electronic_circulations_books_and_media/total_library_circulations_physical_and_digital_electronic,
         per_phys_circ = total_physical_library_circulations_books_and_media/total_library_circulations_physical_and_digital_electronic) %>% 
  rename(total_circ = total_library_circulations_physical_and_digital_electronic) %>% 
  select(institution_name, highest_degree_offered, fyear, total_circ, perc_dig_circ, per_phys_circ) 

top_masters_inst_2020 <- dat2 %>%
  filter(highest_degree_offered == "Master's degree" & fyear == 2020) %>% 
  mutate(avg_circ = mean(total_circ, na.rm = TRUE)) %>% 
  arrange(desc(total_circ)) %>% 
  head(1)

top_masters_inst_2019 <- dat2 %>%
  filter(highest_degree_offered == "Master's degree" & fyear == 2019) %>% 
  mutate(avg_circ = mean(total_circ, na.rm = TRUE)) %>% 
  arrange(desc(total_circ)) %>% 
  head(1)
```

`r top_masters_inst_2020$institution_name` had the highest circulation among the public institutions that offered a Masters degree as its highest degree in 2020 with a circulation of `r format(top_masters_inst_2020$total_circ, scientific = FALSE)`. This was `r round(top_masters_inst_2020$total_circ/top_masters_inst_2020$avg_circ, 5) * 100`% higher than the average circulation for public institutions in this category. 

The previous year, `r top_masters_inst_2019$institution_name` was even higher with a circulation of `r format(top_masters_inst_2019$total_circ, scientific = FALSE)`. This was `r round(top_masters_inst_2019$total_circ/top_masters_inst_2019$avg_circ, 5) * 100`% higher than the average circulation for public institutions in this category. `r top_masters_inst_2019$institution_name` is most likely the largest outlier in this year. 

### Pivoting the data and calculating change over time for CUNY John Jay College of Criminal Justice

Below is an example of calculating change over time. In this case, since the data is in a long format (each school has multiple observations based on the year) I'm going to pivot it into a wide format so John Jay is a single observation with each variable/year combination is represented by a different columns This will allow me to calculate the change over time. In this situationm a 0% change is no change, 100% doubles, 200% triples. Pivoting is a more advanced data wrangling technique. 

What I want to see is if this is a one-off outlier or representative of a larger trend.

```{r echo = FALSE}
john_jay <- dat %>% 
  filter(institution_name == "CUNY John Jay College of Criminal Justice") %>% 
  rename(total_circ = total_library_circulations_physical_and_digital_electronic,
         dig_circ = total_digital_electronic_circulations_books_and_media,
         phys_circ = total_physical_library_circulations_books_and_media) %>%
  select(institution_name, fyear, total_circ, dig_circ, phys_circ) %>% 
  pivot_wider(id_cols = institution_name, names_from = fyear, values_from = c(total_circ, dig_circ, phys_circ)) %>% 
  mutate(from2019_circ_change = (total_circ_2020 - total_circ_2019)/total_circ_2019,
         from2019_dig_circ_change = (dig_circ_2020 - dig_circ_2019)/dig_circ_2019,
         from2019_phys_circ_change = (phys_circ_2020 - phys_circ_2019)/phys_circ_2019)
```

| Type of circulation | 2020 | 2019 | change over time |
|:--------------------|:-----|:-----|:-------|
| Total circulation | `r format(john_jay$total_circ_2020, scientific = FALSE)`|`r format(john_jay$total_circ_2019, scientific = FALSE)`|`r round(john_jay$from2019_circ_change, 4) *100`%|
| Digital circulation | `r format(john_jay$dig_circ_2020, scientific = FALSE)`|`r format(john_jay$dig_circ_2019, scientific = FALSE)`|`r round(john_jay$from2019_dig_circ_change, 4) *100`%|
| Physical circulation | `r format(john_jay$phys_circ_2020, scientific = FALSE)`|`r format(john_jay$phys_circ_2019, scientific = FALSE)`|`r round(john_jay$from2019_phys_circ_change, 4) *100`%|

It clearly seems like a one-off change in the digital circulation so John Jay may not be a repeat outlier. 

